{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "                                                                                                                                                                                                                                                                                        from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from tensorflow.keras.models import load_model #keras framework is used to load our deep learning  model\n",
    "import cv2             #numpy and opencv cv2 libraries is to work with live webcam and images           \n",
    "import numpy as np\n",
    "import tkinter                   #tkinter is used  to create a warning pop up window in order to the user.if he or she is not wearing a mask\n",
    "from tkinter import messagebox\n",
    "import smtplib            #smtplib is being used to define  an smtpclient session object  that is used to send  an alert email if a person is found not wearing a mask\n",
    "from keras.preprocessing import image\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Invalid requirement: '#installing'\n"
     ]
    }
   ],
   "source": [
    "!pip install opencv-python #installing opencv "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize Tkinter\n",
    "root = tkinter.Tk()#Initializing  Tkinter in order to create tk root which is a window  with a little bar and other decoration provided by the window  manager.\n",
    "root.withdraw()#if we don't use this  function the it will cause the app to create a empty root window always which we  don't want.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras as keras\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load trained deep learning model\n",
    "model = load_model('model-090.model')#load model method  to load our deep learning model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Classifier to detect face\n",
    "#we are using opencv haarcascade frontface classifier to detect the face in  the  videoframe so that first we will locate the vision of interest\n",
    "#which in our case in human face ,Once we locate face,we can use our deep learning model loaded over to predict the person is wearing a mask or not\n",
    "face_det_classifier= cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "print(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Capture Video\n",
    "vid_source=cv2.VideoCapture(0)#/In this line we are trying   to capture the live video feed by making use of opencv videocapture method this will  return video from the first web cam from the computer,Please ensurer that the argument inside is 0.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here 0 and 1 are keys and mask and no mask are the values will be display in the rectangle  shape that we are going to draw around faces.\n",
    "# Dictionaries containing details of Wearing Mask and Color of rectangle around face. If wearing mask then color would be \n",
    "# green and if not wearing mask then color of rectangle around face would be red\n",
    "text_dict={0:'Mask ON',1:'No Mask'}\n",
    "rect_color_dict={0:(0,255,0),1:(0,0,255)}\n",
    "#rect_color_dict=it holds the colour of rectangle around the face,0 and 1 are keys [0,255,0]=green colour detection..i.e=MASK is weared and [0,0,255]=Red Colour detection..i.e=NO MASK is weared{Here(0,255,0)and(0,0,255)->represent the colour on BGRB}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "print(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "print(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'source' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-39-a40b66a8f3f0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdestroyAllWindows\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 37\u001b[1;33m \u001b[0msource\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     38\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'source' is not defined"
     ]
    }
   ],
   "source": [
    "#while loop will continously detect the camera feed\n",
    "while(True):\n",
    "\n",
    "    ret,img=vid_source.read()# Here ret is boolean value  that tells whether or not  any frame  is return from the video feed.\n",
    "    gray=cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)#it convert image  file into grayscale,For this we are using cv2 color function;here we are passing each frame along with a parameter(color.BGR2GRAY)\n",
    "    faces=face_det_classifier.detectMultiScale(gray,1.3,5)#face_det_classifier method called as detect multiscale it takes several i/p parameter 1./p grayscale image 2.scale factor which  detect the parameter specifying how much the img size is reduce at  each img  scale by setting it to  1.3 which means that we are reducing the img by 30%.\n",
    "                                                          #3.Means neighbour that depict  how many neighbour each candidate rectangle should have to return,this means that we have multiple faces in the same region then it may draw multiple rectangle  there,so we threw this parameter are telling that it should consider it as  one face.\n",
    "    for (x,y,w,h) in faces:#Here x,y,w,h are coordinates in order to draw the rectangle,w=wide,h=height\n",
    "        face_img = gray[y:y+w,x:x+w]\n",
    "        resized_img = cv2.resize(face_img,(100,100))#here it is croping the image\n",
    "        normalized_img = resized_img/255.0\n",
    "        reshaped_img = np.reshape(normalized_img,(1,100,100,1))\n",
    "        result=model.predict(reshaped_img)#here we are predicting the facemask used to predict function associated with the deep learning model.\n",
    "        label=np.argmax(result,axis=1)[0]\n",
    "        cv2.rectangle(img,(x,y),(x+w,y+h),rect_color_dict[label],2)#rectangle colour\n",
    "        cv2.rectangle(img,(x,y-40),(x+w,y),rect_color_dict[label],-1)#rectangle color\n",
    "        cv2.putText(img, text_dict[label], (x, y-10),cv2.FONT_HERSHEY_SIMPLEX,0.8,(0,0,0),2) #here the text in the rectangle i.e MASK and i.e NO MASK\n",
    "        if (label == 1):#if the label is equal to 1 than you are not wearing a mask and 0 means Wearing a mask.\n",
    "            messagebox.showwarning(\"Warning\",\"Access Denied. Please wear a Face Mask\")\n",
    "                        # Send an email to the administrator if access denied/user not wearing face maskmessage\n",
    "            mail = smtplib.SMTP_SSL(\"smtp.gmail.com\", 465)\n",
    "            mail.login(\"sharmasauravbhai781@gmail.com\", \"dibrugarh\")\n",
    "            mail.sendmail(\"sharmasauravbhai781@gmail.com\",\"callmesaurav861@gmail.com\",\"One Visitor violated Face Mask Policy. See in the camera to recognize user. A Person has been detected without a face mask in the University Campus. Please Alert the authorities.\"\n",
    ")\n",
    "            mail.quit()\n",
    "        else:\n",
    "            pass\n",
    "            break\n",
    "\n",
    "    cv2.imshow('LIVE Video Feed',img)#the camera frame with the name live video feed.\n",
    "    key=cv2.waitKey(1)\n",
    "\n",
    "    if(key==27):#if we are pressing the escape key it will quit\n",
    "        break\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "source.release()\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
